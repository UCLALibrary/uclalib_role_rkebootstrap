---

# Calico CNI Configuration
#---------------------------------------------------------
- name: "Enable automatic host endpoint in Calico on cluster: {{ item.item }}"
  shell: |
    kubectl patch KubeControllersConfiguration default --type=merge --patch='{"spec": {"controllers": {"node": {"hostEndpoint": {"autoCreate": "Enabled"}}}}}'
  environment:
    KUBECONFIG: "{{ kubeconfig_dir }}/kubeconfig_{{ item.item }}"

- name: "Adjust FelixConfiguration to disable fail safe inbound ports on cluster: {{ item.item }}"
  shell: |
    kubectl patch FelixConfiguration default --type=merge --patch='{"spec": {"failsafeInboundHostPorts": []}}'
  environment:
    KUBECONFIG: "{{ kubeconfig_dir }}/kubeconfig_{{ item.item }}"
#---------------------------------------------------------

#  Install cert-manager
#---------------------------------------------------------
- name: "Install cert-manager helm chart on cluster: {{ item.item }}"
  shell: |
    helm repo add jetstack "{{ cert_manager_repo }}"
    helm repo update jetstack
    helm upgrade --install --version "{{ cert_manager_version }}" -n cert-manager --create-namespace cert-manager jetstack/cert-manager --set installCRDs=true
  environment:
    KUBECONFIG: "{{ kubeconfig_dir }}/kubeconfig_{{ item.item }}"
#---------------------------------------------------------

# Install external secrets
#---------------------------------------------------------
- name: "Install external secrets helm chart on cluster: {{ item.item }}"
  shell: |
    helm repo add external-secrets "{{ external_secrets_repo }}"
    helm repo update external-secrets
    helm upgrade --install --version "{{ external_secrets_version }}" -n external-secrets --create-namespace external-secrets external-secrets/external-secrets
  environment:
    KUBECONFIG: "{{ kubeconfig_dir }}/kubeconfig_{{ item.item }}"
#---------------------------------------------------------

# Install MetalLB
#---------------------------------------------------------
- name: "Install MetalLB helm chart on cluster: {{ item.item }}"
  shell: |
    helm repo add metallb "{{ metallb_repo }}"
    helm repo update metallb
    helm upgrade --install --version "{{ metallb_version }}" metallb metallb/metallb --namespace metallb-system --create-namespace
  environment:
    KUBECONFIG: "{{ kubeconfig_dir }}/kubeconfig_{{ item.item }}"
#---------------------------------------------------------

# Prep for CPI/CSI installation
#---------------------------------------------------------
- name: "Create temp directory for storing vSphere installation and config files on cluster: {{ item.item }}"
  tempfile:
    state: directory
    suffix: csibuild
  register: vsphere_config_tempdir

- name: "Clone Rancher-specific vSphere CPI/CSI charts to install on cluster: {{ item.item }}"
  git: 
    repo: "{{ vsphere_cpi_csi_chart_url }}"
    dest: "{{ vsphere_config_tempdir.path }}/vsphere-charts"
#---------------------------------------------------------

# Deploy vSphere Cloud Provider Interface (CPI)
#---------------------------------------------------------
- name: "CPI - Taint all nodes in the cluster: {{ item.item }}"
  shell: |
    kubectl taint nodes --all=true node.cloudprovider.kubernetes.io/uninitialized=true:NoSchedule
  environment:
    KUBECONFIG: "{{ kubeconfig_dir }}/kubeconfig_{{ item.item }}"

- name: "CPI - Deploy Rancher-specific vSphere Cloud Provider Interface helm chart on cluster: {{ item.item }}"
  shell: >
    helm upgrade --install --version "{{ vsphere_cpi_version }}" vsphere-cpi {{ vsphere_config_tempdir.path }}/vsphere-charts/charts/rancher-vsphere-cpi 
    --namespace kube-system --set vCenter.host={{ vcenter_fqdn | quote }} --set vCenter.username={{ vcenter_username | quote }} 
    --set vCenter.password={{ vcenter_user_password | quote }} --set vCenter.datacenters={{ vcenter_datacenter_name | quote }}
  environment:
    KUBECONFIG: "{{ kubeconfig_dir }}/kubeconfig_{{ item.item }}"
  no_log: "{{ disable_log_msg }}"
#---------------------------------------------------------

- name: "Pause for 1 minute to let the Cloud Provider Interface Plug-in finish deploying on cluster: {{ item.item }}"
  pause:
    minutes: 1

# Deploy vSphere Container Storage Plug-in (CSI)
#---------------------------------------------------------
- name: "CSI - Get number of control plane nodes in cluster on cluster: {{ item.item }}"
  shell: |
    kubectl get nodes -l node-role.kubernetes.io/controlplane=true -o name | wc -l
  environment:
    KUBECONFIG: "{{ kubeconfig_dir }}/kubeconfig_{{ item.item }}"
  register: num_controlplane_nodes

- name: "CSI - Deploy Rancher-specific vSphere Container Storage Interface helm chart on cluster: {{ item.item }}"
  shell: >
    helm upgrade --install --version "{{ vsphere_csi_version }}" vsphere-csi {{ vsphere_config_tempdir.path }}/vsphere-charts/charts/rancher-vsphere-csi --namespace {{ vsphere_csi_namespace }} --create-namespace
    --set vCenter.host={{ vcenter_fqdn | quote }} --set vCenter.clusterId={{ item.item }} --set vCenter.datacenters={{ vcenter_datacenter_name | quote }} 
    --set vCenter.username={{ vcenter_username | quote }} --set vCenter.password={{ vcenter_user_password | quote }}
    --set storageClass.datastoreURL={{ vcenter_datastore_url | quote }} --set storageClass.allowVolumeExpansion={{ vcenter_vol_expansion }}
  environment:
    KUBECONFIG: "{{ kubeconfig_dir }}/kubeconfig_{{ item.item }}"
  no_log: "{{ disable_log_msg }}"

- name: "CSI - Patch vSphere Container Storage Plug-in deployment replica count on cluster: {{ item.item }}"
  shell: |
    kubectl --namespace {{ vsphere_csi_namespace }} patch deployment vsphere-csi-controller --type=merge --patch='{"spec":{"replicas": {{ num_controlplane_nodes.stdout }}}}'
  environment:
    KUBECONFIG: "{{ kubeconfig_dir }}/kubeconfig_{{ item.item }}"
  when: num_controlplane_nodes.stdout != 3
#---------------------------------------------------------

- name: "Pause for 1 minute to let all Pods finish deploying on cluster: {{ item.item }}"
  pause:
    minutes: 1

# Install RKE Bootstrap Helm Chart
#---------------------------------------------------------
- name: "Get MetalLB Load Balancer IP address for cluster {{ item.item }}"
  set_fact:
    loadbalancer_ip: "{{ clusters_output.json | json_query(ip_query) | join }}"
  vars:
    ip_query: "data[?id=='{{ item.item }}'].labels.metallbip"

- name: "Install rke bootstrap helm chart on cluster: {{ item.item }}"
  shell: >
    helm upgrade --install --version "{{ rke_bootstrap_version }}" -n uclabootstrap --create-namespace uclabootstrap /etc/ansible/files/rancher/rke_bootstrap
    --set secrets.external_secrets.services.aws.access_key="{{ es_services_access_key }}"
    --set secrets.external_secrets.services.aws.secret_access_key="{{ es_services_secret_access_key }}"
    --set secrets.external_secrets.systems.aws.access_key="{{ es_systems_access_key }}"
    --set secrets.external_secrets.systems.aws.secret_access_key="{{ es_systems_secret_access_key }}"
    --set secrets.external_secrets.apps.aws.access_key="{{ es_apps_access_key }}"
    --set secrets.external_secrets.apps.aws.secret_access_key="{{ es_apps_secret_access_key }}"
    --set secrets.external_secrets.devsupport.aws.access_key="{{ es_devsupport_access_key }}"
    --set secrets.external_secrets.devsupport.aws.secret_access_key="{{ es_devsupport_secret_access_key }}"
    --set secrets.cert_manager.external.sectigo_acme.email="{{ sectigo_acme_email }}"
    --set secrets.cert_manager.external.sectigo_acme.tls_key="{{ sectigo_acme_tls_key }}"
    --set metallb.ipaddresspool.poolname="{{ item.item }}-pool"
    --set metallb.ipaddresspool.ipaddress="{{ loadbalancer_ip }}/32"
    --set metallb.l2advertisement.advname="{{ item.item }}-adv"
  environment:
    KUBECONFIG: "{{ kubeconfig_dir }}/kubeconfig_{{ item.item }}"
  no_log: "{{ disable_log_msg }}"
#---------------------------------------------------------

# Install Ingress Nginx
#---------------------------------------------------------
- name: "Install Ingress Nginx helm chart on cluster: {{ item.item }}"
  shell: > 
    helm repo add ingress-nginx "{{ ingress_nginx_repo }}" ; 
    helm repo update ingress-nginx ;
    helm upgrade --install --version "{{ ingress_nginx_version }}" ingress-nginx ingress-nginx/ingress-nginx 
    --namespace ingress-nginx --create-namespace --set 'controller.ingressClassResource.default=true' --set 'controller.service.externalTrafficPolicy=Local'
  environment:
    KUBECONFIG: "{{ kubeconfig_dir }}/kubeconfig_{{ item.item }}"
#---------------------------------------------------------

# Register Cluster in ArgoCD
#---------------------------------------------------------
- name: "Get Cluster Role Template Binding for User {{ argocd_svc_account_id }} in cluster {{ item.item }}"
  uri:
    url: "{{ rancher_api_url }}/v3/clusters/{{ item.item }}/clusterroletemplatebindings?userId={{ argocd_svc_account_id }}"
    method: GET
    validate_certs: false
    return_content: true
    status_code: 200
    headers:
      Authorization: "Bearer {{ rancher_token }}"
  register: clusterroletemplatebindings_result

- name: "Add Rancher ArgoCD Service Account User {{ argocd_svc_account_id }} as a member of cluster {{ item.item }}"
  uri:
    url: "{{ rancher_api_url }}/v3/clusterroletemplatebindings"
    method: POST
    validate_certs: false
    return_content: true
    status_code: 201
    body_format: json
    body:
      type: "clusterRoleTemplateBinding"
      clusterId: "{{ item.item }}"
      roleTemplateId: "cluster-member"
      userPrincipalId: "local://{{ argocd_svc_account_id }}"
    headers:
      Authorization: "Bearer {{ rancher_token }}"
  when: not clusterroletemplatebindings_result.json.data

- name: "Get name of cluster {{ item.item }}"
  shell: >
    kubectl config current-context
  environment:
    KUBECONFIG: "{{ kubeconfig_dir }}/kubeconfig_{{ item.item }}"
  register: kube_current_context

- name: "Set cluster {{ item.item }} server endpoint URL"
  set_fact:
    cluster_server_url_endpoint: "{{ rancher_api_url }}/k8s/clusters/{{ item.item }}"

- name: "Create temp storage area on ArgoCD cluster host"
  tempfile:
    state: directory
    suffix: "_argocd_cluster_reg"
  register: argocd_config_tempdir
  delegate_to: "{{ argocd_k3s_host }}"
  connection: ssh

- name: "Generate Secret manifest file for {{ item.item }} registration into ArgoCD"
  template: 
    src: "argocd_cluster_secret.j2"
    dest: "{{ argocd_config_tempdir.path }}/argocd_cluster_secret.yaml"
  delegate_to: "{{ argocd_k3s_host }}"
  connection: ssh

- name: "Create {{ item.item }} Secret resource in ArgoCD cluster"
  shell: >
    kubectl -n argocd apply -f {{ argocd_config_tempdir.path }}/argocd_cluster_secret.yaml
  environment:
    KUBECONFIG: "{{ argocd_k3s_kubeconfig }}"
  delegate_to: "{{ argocd_k3s_host }}"
  connection: ssh
#---------------------------------------------------------

# Clean-up for temp directory installation
#---------------------------------------------------------
- name: "Remove temp directory for storing vSphere installation and config files on cluster: {{ item.item }}"
  file:
    path: "{{ vsphere_config_tempdir.path }}"
    state: absent

- name: "Remove temp directory for storing ArgoCD manifest files"
  file:
    path: "{{ argocd_config_tempdir.path }}"
    state: absent 
  delegate_to: "{{ argocd_k3s_host }}"
  connection: ssh
#---------------------------------------------------------
